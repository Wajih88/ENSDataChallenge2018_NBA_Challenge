{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge nos données d'entrainement pour les 30 derniers secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"MatriceTrainDerniere30Seconds.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge nos données test pour les 30 derniers secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"MatriceTestDerniere30Seconds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  781   914 12795 ... 11199 17432  4234]\n"
     ]
    }
   ],
   "source": [
    "Id_test= np.load(\"IdTest.npy\")\n",
    "print Id_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge le fichier de sortie, et recupérer notre label à prédire grace à LabelEncoder de sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "dfy = pd.read_csv(\"challenge_output_data_training_file_nba_challenge.csv\",sep=';')\n",
    "le = LabelEncoder() \n",
    "Y = le.fit_transform(dfy['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare le jeu de donnéees en trainig set et testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#créer le classifieur GaussianNb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#creer le classifier BernouilliNb\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb =  GaussianNB(priors=None)\n",
    "#entrainer le mdéle\n",
    "gnb.fit(X_train, Y_train)\n",
    "#prédire l'outpout\n",
    "ypred_1 = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On évalue les prédictions pour le classifieur GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB accuracy score: 0.710651828299\n"
     ]
    }
   ],
   "source": [
    "#évaluer les prédiCtions\n",
    "accuracy = accuracy_score(Y_test, ypred_1, normalize = True)\n",
    "print('GaussianNB accuracy score: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "gnb =  GaussianNB(priors=None)\n",
    "#entrainer le mdéle\n",
    "gnb.fit(X_train, Y_train)\n",
    "X_test = np.load(\"MatriceTestDerniere30Seconds.npy\")\n",
    "#prédire l'outpout\n",
    "ypred_1 = gnb.predict(X_test)\n",
    "print \"Predicted Value:\",ypred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[982 406]\n",
      " [313 815]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,ypred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha=1,binarize=True,class_prior=None, fit_prior=True)\n",
    "#entrainer le modéle\n",
    "bnb.fit(X_train, Y_train)\n",
    "#prédirel'outpout\n",
    "ypred_2 = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    On évalue les prédictions pour notre classifieur BernouilliB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy score: 0.717408585056\n"
     ]
    }
   ],
   "source": [
    "#évaluer les prédictions\n",
    "accuracy = accuracy_score(Y_test, ypred_2, normalize = True)\n",
    "print('BernoulliNB accuracy score: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha=1,binarize=True,class_prior=None, fit_prior=True)\n",
    "#entrainer le modéle\n",
    "bnb.fit(X_train, Y_train)\n",
    "X_test = np.load(\"MatriceTestDerniere30Seconds.npy\")\n",
    "#prédirel'outpout\n",
    "ypred_2 = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print \"Predicted Value:\",ypred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71104928 0.70508744 0.70298211 0.70775348 0.70206842]\n"
     ]
    }
   ],
   "source": [
    "#Validation croisée\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "xval = cross_val_score(bnb, X, Y, cv=5)\n",
    "print xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71224165 0.70389507 0.70298211 0.70059642 0.69291965]\n"
     ]
    }
   ],
   "source": [
    "#Validation croisée\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "xval = cross_val_score(gnb, X, Y, cv=5)\n",
    "print xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  781     1]\n",
      " [  914     0]\n",
      " [12795     0]\n",
      " ...\n",
      " [11199     1]\n",
      " [17432     0]\n",
      " [ 4234     1]]\n"
     ]
    }
   ],
   "source": [
    "Y_essai1 = np.array([Id_test,ypred_1])\n",
    "Y_essai1 = Y_essai1.T\n",
    "print(Y_essai1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4192L,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('E:\\essaiDerniersecondeBayesGaussionNB.csv', Y_essai1 , delimiter =';', fmt = '%s', header ='ID;Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_essai2 = np.array([Id_test,ypred_2])\n",
    "Y_essai2 = Y_essai2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  781     1]\n",
      " [  914     0]\n",
      " [12795     0]\n",
      " ...\n",
      " [11199     1]\n",
      " [17432     0]\n",
      " [ 4234     1]]\n"
     ]
    }
   ],
   "source": [
    "print Y_essai2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('E:\\essaiDerniersecondeBayesBernoilliNB2.csv', Y_essai2 , delimiter =';', fmt = '%i', header ='ID;Label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
